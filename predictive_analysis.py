# -*- coding: utf-8 -*-
"""Predictive_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tadrRBKdV9OCK1iPbBafjgg0-mtzvVQz

# Introduction

## Identitas Proyek

**Nama:** Davi Sulaiman

**ID Peserta:** MC189D5Y0317  

**Judul Proyek:** Prediksi Risiko Kanker Paru-Paru Menggunakan Machine Learning

## Latar Belakang

Kanker paru-paru adalah penyebab utama kematian akibat kanker secara global, dengan lebih dari 2 juta kasus baru setiap tahun dan tingkat kelangsungan hidup yang rendah, terutama akibat keterlambatan diagnosis dan heterogenitas sel tumor. Penggunaan pendekatan berbasis Machine Learning (ML) menawarkan solusi yang potensial dalam mendeteksi kanker lebih awal secara non-invasif, efisien, dan dapat diandalkan.

Dalam studi oleh **Gao et al. (2023)**, ML terbukti bermanfaat dalam prediksi efektivitas imunoterapi untuk kanker paru-paru melalui analisis biomarker seperti **PD-L1**, **Tumor Mutation Burden (TMB)**, dan **Tumor Microenvironment (TME)**. Mereka menunjukkan bahwa pendekatan _digital biopsy_ melalui AI bisa menggantikan metode konvensional yang mahal dan invasif dalam menilai kandidat pasien untuk terapi imun.

Selanjutnya, **Dritsas dan Trigka (2022)** mengembangkan model prediksi risiko kanker paru berbasis data gejala seperti batuk kronis, sesak napas, dan riwayat merokok menggunakan algoritma Rotation Forest dan menunjukkan hasil yang sangat akurat (AUC mencapai 99,3%). Pendekatan ini menunjukkan bahwa data klinis sederhana sekalipun bisa sangat informatif bila dikombinasikan dengan metode ML yang tepat.

Sementara itu, **Li et al. (2022)** membahas penerapan ML dalam diagnosis, klasifikasi subtipe, dan prediksi prognosis kanker paru-paru dengan menggunakan data **multi-omics** (genomik, transcriptomics, proteomics) serta imaging seperti CT dan histopatologi. Mereka menekankan pentingnya integrasi data besar (big data) dengan algoritma pembelajaran mesin untuk mendukung pengambilan keputusan klinis secara presisi.

## Tujuan Proyek

Melalui proyek ini, kami membangun model klasifikasi risiko kanker paru-paru dengan menggunakan dataset klinis non-invasif yang bersifat terbuka (open dataset). Model ini bertujuan membantu identifikasi individu dengan potensi tinggi mengalami kanker paru-paru untuk mendukung deteksi dini, yang pada akhirnya diharapkan mampu meningkatkan survival rate melalui intervensi lebih awal.

## Ringkasan Dataset

Dataset yang digunakan diperoleh dari platform [Kaggle](https://www.kaggle.com/datasets/akashnath29/lung-cancer-dataset), terdiri dari 3000 observasi dan 16 fitur yang mencakup data demografis, gaya hidup, dan gejala yang berkaitan dengan kanker paru. Target prediksi adalah status `LUNG_CANCER` (Yes/No).

---

Referensi:
- Gao et al., 2023. *Artificial Intelligence and Machine Learning in Lung Cancer Immunotherapy*. J Hematol Oncol, 16(55). https://doi.org/10.1186/s13045-023-01456-y
- Dritsas & Trigka, 2022. *Lung Cancer Risk Prediction with Machine Learning Models*. BDCC, 6(139). https://doi.org/10.3390/bdcc6040139
- Li et al., 2022. *Machine Learning for Lung Cancer Diagnosis, Treatment, and Prognosis*. Genomics, Proteomics & Bioinformatics, 20(5): 850â€“866. https://doi.org/10.1016/j.gpb.2022.11.003
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Submission_Dicoding/

"""## Instalisasi Library"""

!pip install matplotlib seaborn pandas numpy scipy scikit-learn imbalanced-learn xgboost

"""## Import Library (imports.py)"""

# Visualisasi dan Analisis Data
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

# Statistik & Preprocessing
from scipy.stats import skew
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder

# Model Selection & Evaluasi
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    precision_score, recall_score, f1_score
)
from sklearn.datasets import make_classification

# Model Machine Learning
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier

# Penanganan data imbalance
from imblearn.over_sampling import SMOTE

"""## Load Dataset"""

df = pd.read_csv("/content/drive/MyDrive/Submission_Dicoding/dataset.csv")

"""# Data Description

Dataset diambil dari Kaggle dan berisi 3000 observasi dengan 15 fitur input dan 1 target. Semua data bersifat klinis (tidak berbasis citra), cocok untuk skrining berbasis survei atau wawancara.

## Penjelasan Fitur
| Fitur                  | Deskripsi Singkat                                    |
|------------------------|------------------------------------------------------|
| GENDER                 | Jenis kelamin (M/F)                                  |
| AGE                    | Usia dalam tahun                                     |
| SMOKING                | Status merokok (1: Tidak, 2: Ya)                     |
| YELLOW_FINGERS         | Ada/tidaknya jari menguning akibat nikotin          |
| ANXIETY                | Ada/tidaknya kecemasan kronis                        |
| PEER_PRESSURE          | Terpengaruh tekanan teman                            |
| CHRONIC_DISEASE        | Riwayat penyakit kronis                              |
| FATIGUE                | Kelelahan kronis                                     |
| ALLERGY                | Riwayat alergi                                       |
| WHEEZING               | Napas berbunyi                                       |
| ALCOHOL_CONSUMING      | Konsumsi alkohol                                     |
| COUGHING               | Batuk kronis                                         |
| SHORTNESS_OF_BREATH    | Sesak napas                                          |
| SWALLOWING_DIFFICULTY  | Kesulitan menelan                                    |
| CHEST_PAIN             | Nyeri dada                                           |
| LUNG_CANCER            | Target (Yes/No)                                      |

## Explaratory Data Analysis

### Menampilkan data 5 teratas dan terbawah
"""

df.head()

df.tail()

"""### Menampilkan informasi terkait dataset"""

df.info()

"""### Pengecekan baris dan kolom dataset"""

print(f"Dataset memiliki {df.shape[0]} baris dan {df.shape[1]} kolom.")

"""### Menampilkan informasi tipe data pada dataset"""

df.dtypes

"""### Pengecekan Dataset Null"""

df.isnull().sum()

"""### Pengecekan Dataset adanya duplikasi atau tidak"""

print("Jumlah duplikasi: ", df.duplicated().sum())

"""### Melihat describe dataset"""

df.describe()

"""## Preprocessing Dataset

### Menghapus data yang terduplikat
"""

# Hapus duplikasi
df = df.drop_duplicates()

# Verifikasi ulang
print("Jumlah data duplikat setelah dibersihkan:", df.duplicated().sum())

"""### Labelling dataset (ubah yang tipe data object jadi int)"""

# Inisialisasi LabelEncoder
le = LabelEncoder()

# Daftar kolom kategorikal
categorical_columns = ['GENDER', 'SMOKING', 'YELLOW_FINGERS', 'ANXIETY',
                       'PEER_PRESSURE', 'CHRONIC_DISEASE', 'FATIGUE',
                       'ALLERGY', 'WHEEZING', 'ALCOHOL_CONSUMING',
                       'COUGHING', 'SHORTNESS_OF_BREATH',
                       'SWALLOWING_DIFFICULTY', 'CHEST_PAIN', 'LUNG_CANCER']

# Lakukan encoding
for col in categorical_columns:
    df[col] = le.fit_transform(df[col])

print(df['LUNG_CANCER'].value_counts())
sns.countplot(x='LUNG_CANCER', data=df)
plt.title("Distribusi Kelas Target")
plt.show()

"""## Data Understanding"""

df.info()

# Pie Chart
plt.pie(df['LUNG_CANCER'].value_counts(), labels=df['LUNG_CANCER'].value_counts().index, autopct='%1.1f%%')
plt.show()

# Countplot
sns.countplot(x='LUNG_CANCER', data=df, palette='hls')
plt.title('Distribusi LUNG_CANCER')
plt.show()

# Heatmap Korelasi
numerical_df = df.select_dtypes(include=['int64', 'float64'])
plt.figure(figsize=(12, 8))
sns.heatmap(numerical_df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Heatmap Korelasi')
plt.show()

# Boxplot untuk semua kolom
cols_per_row = 3
columns = df.columns.tolist()
num_rows = -(-len(columns) // cols_per_row)

plt.figure(figsize=(15, num_rows * 4))
for i, col in enumerate(columns, 1):
    plt.subplot(num_rows, cols_per_row, i)
    sns.boxplot(y=df[col], color='lightblue')
    plt.title(f'{col}')
    plt.xlabel("")
plt.tight_layout()
plt.show()

"""## Modelling

### Modelling (Mensimulasikan Data Buatan)

#### Preprocessing Dataset Simulasi Data Buatan

#### Split Dataset
"""

X, y = make_classification(n_samples=2998, n_features=5, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f'Total data: {len(X)}, Train: {len(X_train)}, Test: {len(X_test)}')

"""#### Standarisasi Dataset"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""### Models Training

#### Inisialisasi Model
"""

# Inisialisasi model
models = {
    "Logistic Regression": LogisticRegression(max_iter=10000, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=10),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "AdaBoost": AdaBoostClassifier(random_state=42)
}

"""#### Melatih Model"""

# Melatih model
trained_models = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    trained_models[name] = model
    print(f" {name} telah dilatih.")

"""#### Evaluasi Model"""

# Evaluasi model
results = {}
for name, model in trained_models.items():
    y_pred = model.predict(X_test)

    # Menghitung metrik evaluasi
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    conf_matrix = confusion_matrix(y_test, y_pred)

    # Simpan hasil evaluasi
    results[name] = {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1,
        "Confusion Matrix": conf_matrix
    }

    print(f" {name} selesai dievaluasi dengan akurasi (data simulasi buatan): {accuracy:.4f}")

# Tampilkan hasil evaluasi
for model, metrics in results.items():
    print(f"\n Model: {model}")
    for metric, value in metrics.items():
        if metric != "Confusion Matrix":
            print(f"  {metric}: {value:.4f}")
    print("-" * 50)

# Jumlah total model
model_names = list(results.keys())
n_models = len(model_names)

# Buat subplot: 4 kolom per baris
cols = 4
rows = (n_models + cols - 1) // cols  # pembulatan ke atas

fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 5 * rows))

# Flatten axes untuk akses mudah jika hanya 1 baris
axes = axes.flatten()

# Plot masing-masing confusion matrix
for idx, (name, metrics) in enumerate(results.items()):
    sns.heatmap(metrics["Confusion Matrix"], annot=True, fmt="d", cmap="Blues",
                xticklabels=sorted(set(y_test)), yticklabels=sorted(set(y_test)),
                ax=axes[idx])
    axes[idx].set_title(f"Confusion Matrix - {name}")
    axes[idx].set_xlabel("Predicted Label")
    axes[idx].set_ylabel("True Label")

# Kosongkan subplot jika tidak terpakai (jika model tidak kelipatan 3)
for j in range(idx + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()
print("Data Simulasi")

# Ambil nama model dan nilai akurasinya
model_names = list(results.keys())
accuracies = [metrics["Accuracy"] for metrics in results.values()]
accuracy_percent = [f"{acc*100:.2f}%" for acc in accuracies]

# Buat plot
plt.figure(figsize=(10, 6))
bars = sns.barplot(x=accuracies, y=model_names, palette="coolwarm")

# Tambahkan label persentase di ujung bar
for i, (bar, percent) in enumerate(zip(bars.patches, accuracy_percent)):
    plt.text(
        bar.get_width() + 0.01,  # Posisi x: sedikit di luar bar
        bar.get_y() + bar.get_height() / 2,  # Posisi y: tengah-tengah bar
        percent,
        va='center'
    )

# Pengaturan tambahan
plt.xlabel("Akurasi")
plt.title("Perbandingan Akurasi Model (dalam Persentase Data Simulasi Buatan)")
plt.xlim(0, 1.05)
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""### Modelling (mensimulasikan data Klinis)

### Data Preparation (Preprocessing Dataset)

#### Split Dataset
"""

# Pisahkan fitur dan target dari dataset asli
X = df.drop('LUNG_CANCER', axis=1)
y = df['LUNG_CANCER']

# Split data menjadi data latih dan uji
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f'Total data: {len(X)}, Train: {len(X_train)}, Test: {len(X_test)}')

"""#### Standarisasi Dataset"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""### Models Training

#### Inisialisasi Model
"""

# Inisialisasi model
models = {
    "Logistic Regression": LogisticRegression(max_iter=10000, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=10),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "AdaBoost": AdaBoostClassifier(random_state=42)
}

"""#### Melatih Model"""

# Melatih model
trained_models = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    trained_models[name] = model
    print(f" {name} telah dilatih.")

"""#### Evaluasi Model"""

# Evaluasi model
results = {}
for name, model in trained_models.items():
    y_pred = model.predict(X_test)

    # Menghitung metrik evaluasi
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    conf_matrix = confusion_matrix(y_test, y_pred)

    # Simpan hasil evaluasi
    results[name] = {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1,
        "Confusion Matrix": conf_matrix
    }

    print(f" {name} selesai dievaluasi dengan akurasi Data Klinis: {accuracy:.4f}")

# Tampilkan hasil evaluasi
for model, metrics in results.items():
    print(f"\n Model: {model}")
    for metric, value in metrics.items():
        if metric != "Confusion Matrix":
            print(f"  {metric}: {value:.4f}")
    print("-" * 50)

# Jumlah total model
model_names = list(results.keys())
n_models = len(model_names)

# Buat subplot: 4 kolom per baris
cols = 4
rows = (n_models + cols - 1) // cols  # pembulatan ke atas

fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 5 * rows))

# Flatten axes untuk akses mudah jika hanya 1 baris
axes = axes.flatten()

# Plot masing-masing confusion matrix
for idx, (name, metrics) in enumerate(results.items()):
    sns.heatmap(metrics["Confusion Matrix"], annot=True, fmt="d", cmap="Blues",
                xticklabels=sorted(set(y_test)), yticklabels=sorted(set(y_test)),
                ax=axes[idx])
    axes[idx].set_title(f"Confusion Matrix - {name}")
    axes[idx].set_xlabel("Predicted Label")
    axes[idx].set_ylabel("True Label")

# Kosongkan subplot jika tidak terpakai (jika model tidak kelipatan 3)
for j in range(idx + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()
print("Data Klinis")

# Ambil nama model dan nilai akurasinya
model_names = list(results.keys())
accuracies = [metrics["Accuracy"] for metrics in results.values()]
accuracy_percent = [f"{acc*100:.2f}%" for acc in accuracies]

# Buat plot
plt.figure(figsize=(10, 6))
bars = sns.barplot(x=accuracies, y=model_names, palette="coolwarm")

# Tambahkan label persentase di ujung bar
for i, (bar, percent) in enumerate(zip(bars.patches, accuracy_percent)):
    plt.text(
        bar.get_width() + 0.01,  # Posisi x: sedikit di luar bar
        bar.get_y() + bar.get_height() / 2,  # Posisi y: tengah-tengah bar
        percent,
        va='center'
    )

# Pengaturan tambahan
plt.xlabel("Akurasi")
plt.title("Perbandingan Akurasi Model (dalam Persentase Data Klinis)")
plt.xlim(0, 1.05)
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""## Modeling

Tahap *Modeling* merupakan inti dari proses prediksi, di mana berbagai algoritma pembelajaran mesin digunakan untuk mempelajari pola dari data pelatihan dan melakukan prediksi terhadap data pengujian. Dalam penelitian ini, implementasi modeling dilakukan dengan dua pendekatan dataset berbeda: **Data Simulasi** dan **Data Klinis** untuk memberikan perbandingan performa model dalam skenario yang berbeda.

### 1. Logistic Regression

**Deskripsi:**
Model klasifikasi biner yang memodelkan probabilitas kejadian berdasarkan fungsi logistik. Logistic Regression sangat efisien untuk dataset kecil hingga menengah dan bekerja baik jika hubungan antar fitur dan target bersifat linear.

**Parameter:**
* `penalty`: regularisasi L2 (default)
* `C=1.0`: parameter regularisasi (semakin kecil, regularisasi semakin kuat)
* `solver='lbfgs'`
* `max_iter=10000`: digunakan agar model cukup waktu untuk konvergen

**Alasan pemilihan:**
Digunakan sebagai baseline model karena efisien, cepat, dan mudah diinterpretasikan. Model ini menjadi acuan awal untuk membandingkan performa dengan model yang lebih kompleks.

**Performa:**
- **Data Simulasi**: Akurasi 97.00%, Precision 97.00%, Recall 97.00%, F1-Score 97.00%
- **Data Klinis**: Akurasi 49.67%, Precision 49.66%, Recall 49.67%, F1-Score 49.56%

---

### 2. K-Nearest Neighbors (KNN)

**Deskripsi:**
Model berbasis instance yang mengklasifikasi data baru berdasarkan mayoritas kelas dari k tetangga terdekat dalam ruang fitur. Tidak membutuhkan pelatihan eksplisit dan sangat bergantung pada kemiripan data dalam ruang fitur.

**Parameter:**
* `n_neighbors=10`: jumlah tetangga terdekat yang dipertimbangkan
* `metric='minkowski'` (default), menggunakan Euclidean distance sebagai metrik jarak

**Alasan pemilihan:**
Mudah diimplementasikan dan cocok untuk memahami performa awal model berbasis jarak. Dapat memberikan wawasan tentang distribusi spasial data dalam ruang fitur.

**Performa:**
- **Data Simulasi**: Akurasi 97.50%, Precision 97.50%, Recall 97.50%, F1-Score 97.50%
- **Data Klinis**: Akurasi 53.83%, Precision 53.93%, Recall 53.83%, F1-Score 53.55%

---

### 3. Decision Tree

**Deskripsi:**
Model yang memecah data secara rekursif berdasarkan fitur yang paling mengurangi impuritas. Cocok untuk data non-linear dan mudah diinterpretasikan melalui visualisasi pohon keputusan.

**Parameter:**
* `criterion='gini'` (default): pengukuran impuritas
* `max_depth`: tidak diatur, memungkinkan pohon tumbuh penuh (berpotensi overfitting)
* `random_state=42`: untuk hasil yang dapat direproduksi

**Alasan pemilihan:**
Interpretabilitas tinggi dan cepat dalam inferensi. Mampu menangkap interaksi non-linear dalam data secara visual yang mudah dipahami oleh tenaga medis.

**Performa:**
- **Data Simulasi**: Akurasi 96.83%, Precision 96.88%, Recall 96.83%, F1-Score 96.84%
- **Data Klinis**: Akurasi 47.00%, Precision 46.99%, Recall 47.00%, F1-Score 46.97%

---

### 4. Random Forest

**Deskripsi:**
Model ansambel berbasis banyak pohon keputusan (decision trees) yang dilatih pada subset data dan fitur yang berbeda, lalu hasilnya dirata-rata. Mengurangi overfitting dibandingkan decision tree tunggal melalui teknik bagging.

**Parameter:**
* `n_estimators=100`: jumlah pohon dalam hutan
* `max_features='auto'`: fitur dipilih secara acak
* `random_state=42`: untuk hasil yang dapat direproduksi

**Alasan pemilihan:**
Lebih stabil, tahan terhadap overfitting, dan cocok untuk dataset menengah. Dapat menangani noise dan variasi dalam data klinis yang kompleks.

**Performa:**
- **Data Simulasi**: Akurasi 98.17%, Precision 98.18%, Recall 98.17%, F1-Score 98.17%
- **Data Klinis**: Akurasi 53.67%, Precision 53.67%, Recall 53.67%, F1-Score 53.65%

---

### 5. Gradient Boosting

**Deskripsi:**
Model ansambel yang membangun model secara bertahap, memperbaiki kesalahan prediksi model sebelumnya menggunakan pendekatan *gradient descent*. Fokus pada kesalahan prediksi sebelumnya untuk perbaikan berurutan.

**Parameter:**
* `n_estimators=100`: jumlah model berurutan
* `learning_rate=0.1`: mengontrol kontribusi setiap model ke prediksi final
* `random_state=42`: untuk hasil yang dapat direproduksi

**Alasan pemilihan:**
Sangat akurat dalam banyak kompetisi klasifikasi, walaupun lebih lambat dibanding Random Forest. Mampu memperbaiki prediksi secara berurutan sehingga berpotensi lebih baik dalam penanganan kasus sulit.

**Performa:**
- **Data Simulasi**: Akurasi 98.00%, Precision 98.02%, Recall 98.00%, F1-Score 98.00%
- **Data Klinis**: Akurasi 55.50%, Precision 55.55%, Recall 55.50%, F1-Score 55.40%

---

### 6. AdaBoost

**Deskripsi:**
Model boosting yang melatih model sederhana secara berurutan dan menyesuaikan bobot pada data yang sebelumnya salah prediksi. Fokus pada sampel yang sulit diklasifikasi.

**Parameter:**
* `n_estimators=50`: jumlah model berurutan
* `learning_rate=1.0`: kontrol kontribusi setiap model
* `random_state=42`: untuk hasil yang dapat direproduksi

**Alasan pemilihan:**
Mengatasi bias, terutama ketika model dasar lemah, dan cukup efisien. Baik untuk situasi di mana beberapa kasus khusus sulit dideteksi oleh model lain.

**Performa:**
- **Data Simulasi**: Akurasi 97.50%, Precision 97.50%, Recall 97.50%, F1-Score 97.50%
- **Data Klinis**: Akurasi 51.00%, Precision 51.00%, Recall 51.00%, F1-Score 51.00%

---

### 7. XGBoost

**Deskripsi:**
Varian efisien dari gradient boosting dengan kemampuan regularisasi tambahan dan optimasi yang lebih baik. Sangat populer dalam kompetisi ML karena akurasi tinggi dan performa komputasi yang efisien.

**Parameter:**
* `use_label_encoder=False`
* `eval_metric='logloss'`
* `n_estimators=100`: jumlah model berurutan
* `learning_rate=0.1`: kontrol kontribusi setiap model
* `random_state=42`: untuk hasil yang dapat direproduksi

**Alasan pemilihan:**
Presisi tinggi dan efisien dalam menangani missing values serta fitur dalam skala besar. Terkenal dengan performa superior dalam berbagai kompetisi ML dan aplikasi dunia nyata.

**Performa:**
- **Data Simulasi**: Akurasi 97.83%, Precision 97.84%, Recall 97.83%, F1-Score 97.83%
- **Data Klinis**: Akurasi 51.17%, Precision 51.17%, Recall 51.17%, F1-Score 51.12%

---

## Perbandingan Performa Model

### Data Simulasi vs Data Klinis

Terdapat perbedaan signifikan pada performa model antara data simulasi dan data klinis nyata:

#### Data Simulasi
Data simulasi dibuat dengan fungsi `make_classification()` dari scikit-learn yang menghasilkan data sintetis dengan pola yang mudah dikenali:

```python
X, y = make_classification(n_samples=2998, n_features=5, random_state=42)
```

Semua model menunjukkan performa sangat tinggi (96.83% - 98.17%), dengan Random Forest sebagai model terbaik.

#### Data Klinis
Data klinis nyata berasal dari dataset kanker paru-paru dengan variabel target 'LUNG_CANCER':

```python
X = df.drop('LUNG_CANCER', axis=1)
y = df['LUNG_CANCER']
```

Performa pada data klinis jauh lebih rendah (47.00% - 55.50%), menunjukkan kompleksitas dan tantangan pada data medis nyata dibandingkan data simulasi.

### Tabel Perbandingan Performa Model

| Model | Data Simulasi |  |  |  | Data Klinis |  |  |  |
|-------|---------------|--------------|--------------|--------------|-------------|-------------|-------------|-------------|
|  | **Accuracy** | **Precision** | **Recall** | **F1-Score** | **Accuracy** | **Precision** | **Recall** | **F1-Score** |
| Logistic Regression | 0.9700 | 0.9700 | 0.9700 | 0.9700 | 0.4967 | 0.4966 | 0.4967 | 0.4956 |
| Random Forest | **0.9817** | **0.9818** | **0.9817** | **0.9817** | 0.5367 | 0.5367 | 0.5367 | 0.5365 |
| XGBoost | 0.9783 | 0.9784 | 0.9783 | 0.9783 | 0.5117 | 0.5117 | 0.5117 | 0.5112 |
| K-Nearest Neighbors | 0.9750 | 0.9750 | 0.9750 | 0.9750 | 0.5383 | 0.5393 | 0.5383 | 0.5355 |
| Decision Tree | 0.9683 | 0.9688 | 0.9683 | 0.9684 | 0.4700 | 0.4699 | 0.4700 | 0.4697 |
| Gradient Boosting | 0.9800 | 0.9802 | 0.9800 | 0.9800 | **0.5550** | **0.5555** | **0.5550** | **0.5540** |
| AdaBoost | 0.9750 | 0.9750 | 0.9750 | 0.9750 | 0.5100 | 0.5100 | 0.5100 | 0.5100 |

---

# References

- Gao et al., 2023. *Artificial Intelligence and Machine Learning in Lung Cancer Immunotherapy*. Journal of Hematology & Oncology, 16(55). [https://doi.org/10.1186/s13045-023-01456-y](https://doi.org/10.1186/s13045-023-01456-y)  
- Dritsas & Trigka, 2022. *Lung Cancer Risk Prediction with Machine Learning Models*. BDCC, 6(139). [https://doi.org/10.3390/bdcc6040139](https://doi.org/10.3390/bdcc6040139)  
- Li et al., 2022. *Machine Learning for Lung Cancer Diagnosis, Treatment, and Prognosis*. Genomics, Proteomics & Bioinformatics, 20(5): 850â€“866. [https://doi.org/10.1016/j.gpb.2022.11.003](https://doi.org/10.1016/j.gpb.2022.11.003)
"""

