# -*- coding: utf-8 -*-
"""Predictive_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tadrRBKdV9OCK1iPbBafjgg0-mtzvVQz
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Submission_Dicoding/

"""## Instalisasi Library"""

!pip install matplotlib seaborn pandas numpy scipy scikit-learn imbalanced-learn xgboost

"""## Import Library (imports.py)"""

# Visualisasi dan Analisis Data
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

# Statistik & Preprocessing
from scipy.stats import skew
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder

# Model Selection & Evaluasi
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    precision_score, recall_score, f1_score
)
from sklearn.datasets import make_classification

# Model Machine Learning
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier

# Penanganan data imbalance
from imblearn.over_sampling import SMOTE

"""## Load Dataset"""

df = pd.read_csv("/content/drive/MyDrive/Submission_Dicoding/dataset.csv")

"""## Explaratory Data Analysis

### Menampilkan data 5 teratas dan terbawah
"""

df.head()

df.tail()

"""### Menampilkan informasi terkait dataset"""

df.info()

"""### Pengecekan baris dan kolom dataset"""

print(f"Dataset memiliki {df.shape[0]} baris dan {df.shape[1]} kolom.")

"""### Menampilkan informasi tipe data pada dataset"""

df.dtypes

"""### Pengecekan Dataset Null"""

df.isnull().sum()

"""### Pengecekan Dataset adanya duplikasi atau tidak"""

print("Jumlah duplikasi: ", df.duplicated().sum())

"""### Melihat describe dataset"""

df.describe()

"""## Preprocessing Dataset

### Menghapus data yang terduplikat
"""

# Hapus duplikasi
df = df.drop_duplicates()

# Verifikasi ulang
print("Jumlah data duplikat setelah dibersihkan:", df.duplicated().sum())

"""### Labelling dataset (ubah yang tipe data object jadi int)"""

# Inisialisasi LabelEncoder
le = LabelEncoder()

# Daftar kolom kategorikal
categorical_columns = ['GENDER', 'SMOKING', 'YELLOW_FINGERS', 'ANXIETY',
                       'PEER_PRESSURE', 'CHRONIC_DISEASE', 'FATIGUE',
                       'ALLERGY', 'WHEEZING', 'ALCOHOL_CONSUMING',
                       'COUGHING', 'SHORTNESS_OF_BREATH',
                       'SWALLOWING_DIFFICULTY', 'CHEST_PAIN', 'LUNG_CANCER']

# Lakukan encoding
for col in categorical_columns:
    df[col] = le.fit_transform(df[col])

"""## Data Understanding"""

df.info()

# Pie Chart
plt.pie(df['LUNG_CANCER'].value_counts(), labels=df['LUNG_CANCER'].value_counts().index, autopct='%1.1f%%')
plt.show()

# Countplot
sns.countplot(x='LUNG_CANCER', data=df, palette='hls')
plt.title('Distribusi LUNG_CANCER')
plt.show()

# Heatmap Korelasi
numerical_df = df.select_dtypes(include=['int64', 'float64'])
plt.figure(figsize=(12, 8))
sns.heatmap(numerical_df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Heatmap Korelasi')
plt.show()

# Boxplot untuk semua kolom
cols_per_row = 3
columns = df.columns.tolist()
num_rows = -(-len(columns) // cols_per_row)

plt.figure(figsize=(15, num_rows * 4))
for i, col in enumerate(columns, 1):
    plt.subplot(num_rows, cols_per_row, i)
    sns.boxplot(y=df[col], color='lightblue')
    plt.title(f'{col}')
    plt.xlabel("")
plt.tight_layout()
plt.show()

"""## Modelling

### Data Preparation (Preprocessing Dataset)

#### Split Dataset
"""

X, y = make_classification(n_samples=2998, n_features=5, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f'Total data: {len(X)}, Train: {len(X_train)}, Test: {len(X_test)}')

"""#### Standarisasi Dataset"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""### Models Training

#### Inisialisasi Model
"""

# Inisialisasi model
models = {
    "Logistic Regression": LogisticRegression(max_iter=10000, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=10),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "AdaBoost": AdaBoostClassifier(random_state=42)
}

"""#### Melatih Model"""

# Melatih model
trained_models = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    trained_models[name] = model
    print(f" {name} telah dilatih.")

"""#### Evaluasi Model"""

# Evaluasi model
results = {}
for name, model in trained_models.items():
    y_pred = model.predict(X_test)

    # Menghitung metrik evaluasi
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    conf_matrix = confusion_matrix(y_test, y_pred)

    # Simpan hasil evaluasi
    results[name] = {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1,
        "Confusion Matrix": conf_matrix
    }

    print(f" {name} selesai dievaluasi dengan akurasi: {accuracy:.4f}")

# Tampilkan hasil evaluasi
for model, metrics in results.items():
    print(f"\n Model: {model}")
    for metric, value in metrics.items():
        if metric != "Confusion Matrix":
            print(f"  {metric}: {value:.4f}")
    print("-" * 50)

# Visualisasi Confusion Matrix untuk setiap model
for name, metrics in results.items():
    plt.figure(figsize=(6, 5))
    sns.heatmap(metrics["Confusion Matrix"], annot=True, fmt="d", cmap="Blues",
                xticklabels=sorted(set(y_test)), yticklabels=sorted(set(y_test)))
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.title(f"Confusion Matrix - {name}")
    plt.tight_layout()
    plt.show()

# Ambil nama model dan nilai akurasinya
model_names = list(results.keys())
accuracies = [metrics["Accuracy"] for metrics in results.values()]
accuracy_percent = [f"{acc*100:.2f}%" for acc in accuracies]

# Buat plot
plt.figure(figsize=(10, 6))
bars = sns.barplot(x=accuracies, y=model_names, palette="coolwarm")

# Tambahkan label persentase di ujung bar
for i, (bar, percent) in enumerate(zip(bars.patches, accuracy_percent)):
    plt.text(
        bar.get_width() + 0.01,  # Posisi x: sedikit di luar bar
        bar.get_y() + bar.get_height() / 2,  # Posisi y: tengah-tengah bar
        percent,
        va='center'
    )

# Pengaturan tambahan
plt.xlabel("Akurasi")
plt.title("Perbandingan Akurasi Model (dalam Persentase)")
plt.xlim(0, 1.05)
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""## üîç **Evaluasi Model Klasifikasi Kanker Paru-Paru**

### 1. **Logistic Regression**

* **Akurasi**: 97.00%
* **Precision / Recall / F1-Score**: Semuanya 97.00%
* ‚úÖ **Stabil dan efisien**, cocok sebagai baseline model dengan performa cukup tinggi dan konsisten.

### 2. **Random Forest**

* **Akurasi**: **98.17%**
* **Precision**: 98.18%
* **Recall & F1-Score**: 98.17%
* ü•á **Model dengan performa terbaik**, sangat kuat dalam generalisasi dan menangani kompleksitas fitur tanpa overfitting berlebih.

### 3. **XGBoost**

* **Akurasi**: 97.83%
* **Precision**: 97.84%
* **Recall & F1-Score**: 97.83%
* ‚ö° Performa tinggi dan efisien dalam menangani outlier dan fitur non-linear, mendekati Random Forest.

### 4. **K-Nearest Neighbors (KNN)**

* **Akurasi / Precision / Recall / F1-Score**: 97.50%
* üîÑ Model sederhana dan efektif, cocok untuk data yang tidak terlalu besar, meskipun sensitif terhadap pemilihan parameter *k*.

### 5. **Decision Tree**

* **Akurasi**: 96.83%
* **Precision**: 96.88%
* **Recall**: 96.83%
* **F1-Score**: 96.84%
* üìâ Kinerja terendah dibanding model lain karena sifatnya yang mudah overfitting tanpa metode pemangkasan.

### 6. **Gradient Boosting**

* **Akurasi**: 98.00%
* **Precision**: 98.02%
* **Recall & F1-Score**: 98.00%
* üèÜ Salah satu model dengan **stabilitas dan presisi tinggi**, unggul dalam menangani pola kompleks.

### 7. **AdaBoost**

* **Akurasi / Precision / Recall / F1-Score**: 97.50%
* ‚ú≥Ô∏è Model boosting klasik yang memberi bobot pada data sulit. Efektif namun sedikit kalah dari Gradient Boosting dan Random Forest.

---

## üìä **Perbandingan Singkat**

| Model               | Accuracy   | Precision  | Recall     | F1-Score   |
| ------------------- | ---------- | ---------- | ---------- | ---------- |
| Logistic Regression | 0.9700     | 0.9700     | 0.9700     | 0.9700     |
| Random Forest       | **0.9817** | **0.9818** | **0.9817** | **0.9817** |
| XGBoost             | 0.9783     | 0.9784     | 0.9783     | 0.9783     |
| KNN                 | 0.9750     | 0.9750     | 0.9750     | 0.9750     |
| Decision Tree       | 0.9683     | 0.9688     | 0.9683     | 0.9684     |
| Gradient Boosting   | 0.9800     | 0.9802     | 0.9800     | 0.9800     |
| AdaBoost            | 0.9750     | 0.9750     | 0.9750     | 0.9750     |

---

## üéØ **Kesimpulan**

* **Random Forest** memberikan performa terbaik secara keseluruhan.
* **Gradient Boosting** dan **XGBoost** juga menunjukkan hasil luar biasa dan cocok untuk deployment model klasifikasi medis.
* **Logistic Regression** tetap relevan karena kesederhanaannya dan interpretabilitas tinggi, meskipun tidak setinggi ensemble method.


"""

