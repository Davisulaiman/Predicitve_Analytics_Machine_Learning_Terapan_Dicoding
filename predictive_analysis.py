# -*- coding: utf-8 -*-
"""Predictive_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tadrRBKdV9OCK1iPbBafjgg0-mtzvVQz

# Introduction

## Identitas Proyek

**Nama:** Davi Sulaiman

**ID Peserta:** MC189D5Y0317  

**Judul Proyek:** Prediksi Risiko Kanker Paru-Paru Menggunakan Machine Learning

## Latar Belakang

Kanker paru-paru adalah penyebab utama kematian akibat kanker secara global, dengan lebih dari 2 juta kasus baru setiap tahun dan tingkat kelangsungan hidup yang rendah, terutama akibat keterlambatan diagnosis dan heterogenitas sel tumor. Penggunaan pendekatan berbasis Machine Learning (ML) menawarkan solusi yang potensial dalam mendeteksi kanker lebih awal secara non-invasif, efisien, dan dapat diandalkan.

Dalam studi oleh **Gao et al. (2023)**, ML terbukti bermanfaat dalam prediksi efektivitas imunoterapi untuk kanker paru-paru melalui analisis biomarker seperti **PD-L1**, **Tumor Mutation Burden (TMB)**, dan **Tumor Microenvironment (TME)**. Mereka menunjukkan bahwa pendekatan _digital biopsy_ melalui AI bisa menggantikan metode konvensional yang mahal dan invasif dalam menilai kandidat pasien untuk terapi imun.

Selanjutnya, **Dritsas dan Trigka (2022)** mengembangkan model prediksi risiko kanker paru berbasis data gejala seperti batuk kronis, sesak napas, dan riwayat merokok menggunakan algoritma Rotation Forest dan menunjukkan hasil yang sangat akurat (AUC mencapai 99,3%). Pendekatan ini menunjukkan bahwa data klinis sederhana sekalipun bisa sangat informatif bila dikombinasikan dengan metode ML yang tepat.

Sementara itu, **Li et al. (2022)** membahas penerapan ML dalam diagnosis, klasifikasi subtipe, dan prediksi prognosis kanker paru-paru dengan menggunakan data **multi-omics** (genomik, transcriptomics, proteomics) serta imaging seperti CT dan histopatologi. Mereka menekankan pentingnya integrasi data besar (big data) dengan algoritma pembelajaran mesin untuk mendukung pengambilan keputusan klinis secara presisi.

## Tujuan Proyek

Melalui proyek ini, kami membangun model klasifikasi risiko kanker paru-paru dengan menggunakan dataset klinis non-invasif yang bersifat terbuka (open dataset). Model ini bertujuan membantu identifikasi individu dengan potensi tinggi mengalami kanker paru-paru untuk mendukung deteksi dini, yang pada akhirnya diharapkan mampu meningkatkan survival rate melalui intervensi lebih awal.

## Ringkasan Dataset

Dataset yang digunakan diperoleh dari platform [Kaggle](https://www.kaggle.com/datasets/akashnath29/lung-cancer-dataset), terdiri dari 3000 observasi dan 16 fitur yang mencakup data demografis, gaya hidup, dan gejala yang berkaitan dengan kanker paru. Target prediksi adalah status `LUNG_CANCER` (Yes/No).

---

Referensi:
- Gao et al., 2023. *Artificial Intelligence and Machine Learning in Lung Cancer Immunotherapy*. J Hematol Oncol, 16(55). https://doi.org/10.1186/s13045-023-01456-y
- Dritsas & Trigka, 2022. *Lung Cancer Risk Prediction with Machine Learning Models*. BDCC, 6(139). https://doi.org/10.3390/bdcc6040139
- Li et al., 2022. *Machine Learning for Lung Cancer Diagnosis, Treatment, and Prognosis*. Genomics, Proteomics & Bioinformatics, 20(5): 850–866. https://doi.org/10.1016/j.gpb.2022.11.003
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Submission_Dicoding/

"""## Instalisasi Library"""

!pip install matplotlib seaborn pandas numpy scipy scikit-learn imbalanced-learn xgboost

"""## Import Library (imports.py)"""

# Visualisasi dan Analisis Data
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

# Statistik & Preprocessing
from scipy.stats import skew
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder

# Model Selection & Evaluasi
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    precision_score, recall_score, f1_score
)
from sklearn.datasets import make_classification

# Model Machine Learning
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier

# Penanganan data imbalance
from imblearn.over_sampling import SMOTE

"""## Load Dataset"""

df = pd.read_csv("/content/drive/MyDrive/Submission_Dicoding/dataset.csv")

"""# Data Description

Dataset diambil dari Kaggle dan berisi 3000 observasi dengan 15 fitur input dan 1 target. Semua data bersifat klinis (tidak berbasis citra), cocok untuk skrining berbasis survei atau wawancara.

## Penjelasan Fitur
| Fitur                  | Deskripsi Singkat                                    |
|------------------------|------------------------------------------------------|
| GENDER                 | Jenis kelamin (M/F)                                  |
| AGE                    | Usia dalam tahun                                     |
| SMOKING                | Status merokok (1: Tidak, 2: Ya)                     |
| YELLOW_FINGERS         | Ada/tidaknya jari menguning akibat nikotin          |
| ANXIETY                | Ada/tidaknya kecemasan kronis                        |
| PEER_PRESSURE          | Terpengaruh tekanan teman                            |
| CHRONIC_DISEASE        | Riwayat penyakit kronis                              |
| FATIGUE                | Kelelahan kronis                                     |
| ALLERGY                | Riwayat alergi                                       |
| WHEEZING               | Napas berbunyi                                       |
| ALCOHOL_CONSUMING      | Konsumsi alkohol                                     |
| COUGHING               | Batuk kronis                                         |
| SHORTNESS_OF_BREATH    | Sesak napas                                          |
| SWALLOWING_DIFFICULTY  | Kesulitan menelan                                    |
| CHEST_PAIN             | Nyeri dada                                           |
| LUNG_CANCER            | Target (Yes/No)                                      |

## Explaratory Data Analysis

### Menampilkan data 5 teratas dan terbawah
"""

df.head()

df.tail()

"""### Menampilkan informasi terkait dataset"""

df.info()

"""### Pengecekan baris dan kolom dataset"""

print(f"Dataset memiliki {df.shape[0]} baris dan {df.shape[1]} kolom.")

"""### Menampilkan informasi tipe data pada dataset"""

df.dtypes

"""### Pengecekan Dataset Null"""

df.isnull().sum()

"""### Pengecekan Dataset adanya duplikasi atau tidak"""

print("Jumlah duplikasi: ", df.duplicated().sum())

"""### Melihat describe dataset"""

df.describe()

"""## Preprocessing Dataset

### Menghapus data yang terduplikat
"""

# Hapus duplikasi
df = df.drop_duplicates()

# Verifikasi ulang
print("Jumlah data duplikat setelah dibersihkan:", df.duplicated().sum())

"""### Labelling dataset (ubah yang tipe data object jadi int)"""

# Inisialisasi LabelEncoder
le = LabelEncoder()

# Daftar kolom kategorikal
categorical_columns = ['GENDER', 'SMOKING', 'YELLOW_FINGERS', 'ANXIETY',
                       'PEER_PRESSURE', 'CHRONIC_DISEASE', 'FATIGUE',
                       'ALLERGY', 'WHEEZING', 'ALCOHOL_CONSUMING',
                       'COUGHING', 'SHORTNESS_OF_BREATH',
                       'SWALLOWING_DIFFICULTY', 'CHEST_PAIN', 'LUNG_CANCER']

# Lakukan encoding
for col in categorical_columns:
    df[col] = le.fit_transform(df[col])

print(df['LUNG_CANCER'].value_counts())
sns.countplot(x='LUNG_CANCER', data=df)
plt.title("Distribusi Kelas Target")
plt.show()

"""## Data Understanding"""

df.info()

# Pie Chart
plt.pie(df['LUNG_CANCER'].value_counts(), labels=df['LUNG_CANCER'].value_counts().index, autopct='%1.1f%%')
plt.show()

# Countplot
sns.countplot(x='LUNG_CANCER', data=df, palette='hls')
plt.title('Distribusi LUNG_CANCER')
plt.show()

# Heatmap Korelasi
numerical_df = df.select_dtypes(include=['int64', 'float64'])
plt.figure(figsize=(12, 8))
sns.heatmap(numerical_df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Heatmap Korelasi')
plt.show()

# Boxplot untuk semua kolom
cols_per_row = 3
columns = df.columns.tolist()
num_rows = -(-len(columns) // cols_per_row)

plt.figure(figsize=(15, num_rows * 4))
for i, col in enumerate(columns, 1):
    plt.subplot(num_rows, cols_per_row, i)
    sns.boxplot(y=df[col], color='lightblue')
    plt.title(f'{col}')
    plt.xlabel("")
plt.tight_layout()
plt.show()

"""## Modelling

### Modelling (Mensimulasikan Data Buatan)
"""

X, y = make_classification(n_samples=2998, n_features=5, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f'Total data: {len(X)}, Train: {len(X_train)}, Test: {len(X_test)}')

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Inisialisasi model
models = {
    "Logistic Regression": LogisticRegression(max_iter=10000, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=10),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "AdaBoost": AdaBoostClassifier(random_state=42)
}

# Melatih model
trained_models = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    trained_models[name] = model
    print(f" {name} telah dilatih.")

# Evaluasi model
results = {}
for name, model in trained_models.items():
    y_pred = model.predict(X_test)

    # Menghitung metrik evaluasi
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    conf_matrix = confusion_matrix(y_test, y_pred)

    # Simpan hasil evaluasi
    results[name] = {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1,
        "Confusion Matrix": conf_matrix
    }

    print(f" {name} selesai dievaluasi dengan akurasi: {accuracy:.4f}")

# Tampilkan hasil evaluasi
for model, metrics in results.items():
    print(f"\n Model: {model}")
    for metric, value in metrics.items():
        if metric != "Confusion Matrix":
            print(f"  {metric}: {value:.4f}")
    print("-" * 50)

# Jumlah total model
model_names = list(results.keys())
n_models = len(model_names)

# Buat subplot: 4 kolom per baris
cols = 4
rows = (n_models + cols - 1) // cols  # pembulatan ke atas

fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 5 * rows))

# Flatten axes untuk akses mudah jika hanya 1 baris
axes = axes.flatten()

# Plot masing-masing confusion matrix
for idx, (name, metrics) in enumerate(results.items()):
    sns.heatmap(metrics["Confusion Matrix"], annot=True, fmt="d", cmap="Blues",
                xticklabels=sorted(set(y_test)), yticklabels=sorted(set(y_test)),
                ax=axes[idx])
    axes[idx].set_title(f"Confusion Matrix - {name}")
    axes[idx].set_xlabel("Predicted Label")
    axes[idx].set_ylabel("True Label")

# Kosongkan subplot jika tidak terpakai (jika model tidak kelipatan 3)
for j in range(idx + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

# Ambil nama model dan nilai akurasinya
model_names = list(results.keys())
accuracies = [metrics["Accuracy"] for metrics in results.values()]
accuracy_percent = [f"{acc*100:.2f}%" for acc in accuracies]

# Buat plot
plt.figure(figsize=(10, 6))
bars = sns.barplot(x=accuracies, y=model_names, palette="coolwarm")

# Tambahkan label persentase di ujung bar
for i, (bar, percent) in enumerate(zip(bars.patches, accuracy_percent)):
    plt.text(
        bar.get_width() + 0.01,  # Posisi x: sedikit di luar bar
        bar.get_y() + bar.get_height() / 2,  # Posisi y: tengah-tengah bar
        percent,
        va='center'
    )

# Pengaturan tambahan
plt.xlabel("Akurasi")
plt.title("Perbandingan Akurasi Model (dalam Persentase)")
plt.xlim(0, 1.05)
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""### Modelling (mensimulasikan data Klinis)

### Data Preparation (Preprocessing Dataset)

#### Split Dataset
"""

# Pisahkan fitur dan target dari dataset asli
X = df.drop('LUNG_CANCER', axis=1)
y = df['LUNG_CANCER']

# Split data menjadi data latih dan uji
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f'Total data: {len(X)}, Train: {len(X_train)}, Test: {len(X_test)}')

"""#### Standarisasi Dataset"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""### Models Training

#### Inisialisasi Model
"""

# Inisialisasi model
models = {
    "Logistic Regression": LogisticRegression(max_iter=10000, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=10),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "AdaBoost": AdaBoostClassifier(random_state=42)
}

"""#### Melatih Model"""

# Melatih model
trained_models = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    trained_models[name] = model
    print(f" {name} telah dilatih.")

"""#### Evaluasi Model"""

# Evaluasi model
results = {}
for name, model in trained_models.items():
    y_pred = model.predict(X_test)

    # Menghitung metrik evaluasi
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    conf_matrix = confusion_matrix(y_test, y_pred)

    # Simpan hasil evaluasi
    results[name] = {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1,
        "Confusion Matrix": conf_matrix
    }

    print(f" {name} selesai dievaluasi dengan akurasi: {accuracy:.4f}")

# Tampilkan hasil evaluasi
for model, metrics in results.items():
    print(f"\n Model: {model}")
    for metric, value in metrics.items():
        if metric != "Confusion Matrix":
            print(f"  {metric}: {value:.4f}")
    print("-" * 50)

# Jumlah total model
model_names = list(results.keys())
n_models = len(model_names)

# Buat subplot: 4 kolom per baris
cols = 4
rows = (n_models + cols - 1) // cols  # pembulatan ke atas

fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 5 * rows))

# Flatten axes untuk akses mudah jika hanya 1 baris
axes = axes.flatten()

# Plot masing-masing confusion matrix
for idx, (name, metrics) in enumerate(results.items()):
    sns.heatmap(metrics["Confusion Matrix"], annot=True, fmt="d", cmap="Blues",
                xticklabels=sorted(set(y_test)), yticklabels=sorted(set(y_test)),
                ax=axes[idx])
    axes[idx].set_title(f"Confusion Matrix - {name}")
    axes[idx].set_xlabel("Predicted Label")
    axes[idx].set_ylabel("True Label")

# Kosongkan subplot jika tidak terpakai (jika model tidak kelipatan 3)
for j in range(idx + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

# Ambil nama model dan nilai akurasinya
model_names = list(results.keys())
accuracies = [metrics["Accuracy"] for metrics in results.values()]
accuracy_percent = [f"{acc*100:.2f}%" for acc in accuracies]

# Buat plot
plt.figure(figsize=(10, 6))
bars = sns.barplot(x=accuracies, y=model_names, palette="coolwarm")

# Tambahkan label persentase di ujung bar
for i, (bar, percent) in enumerate(zip(bars.patches, accuracy_percent)):
    plt.text(
        bar.get_width() + 0.01,  # Posisi x: sedikit di luar bar
        bar.get_y() + bar.get_height() / 2,  # Posisi y: tengah-tengah bar
        percent,
        va='center'
    )

# Pengaturan tambahan
plt.xlabel("Akurasi")
plt.title("Perbandingan Akurasi Model (dalam Persentase)")
plt.xlim(0, 1.05)
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""## 🔍 **Evaluasi Model Klasifikasi Kanker Paru-Paru**

### 1. **Logistic Regression**

* **Akurasi**: 97.00%
* **Precision / Recall / F1-Score**: Semuanya 97.00%
* ✅ **Stabil dan efisien**, cocok sebagai baseline model dengan performa cukup tinggi dan konsisten.

### 2. **Random Forest**

* **Akurasi**: **98.17%**
* **Precision**: 98.18%
* **Recall & F1-Score**: 98.17%
* 🥇 **Model dengan performa terbaik**, sangat kuat dalam generalisasi dan menangani kompleksitas fitur tanpa overfitting berlebih.

### 3. **XGBoost**

* **Akurasi**: 97.83%
* **Precision**: 97.84%
* **Recall & F1-Score**: 97.83%
* ⚡ Performa tinggi dan efisien dalam menangani outlier dan fitur non-linear, mendekati Random Forest.

### 4. **K-Nearest Neighbors (KNN)**

* **Akurasi / Precision / Recall / F1-Score**: 97.50%
* 🔄 Model sederhana dan efektif, cocok untuk data yang tidak terlalu besar, meskipun sensitif terhadap pemilihan parameter *k*.

### 5. **Decision Tree**

* **Akurasi**: 96.83%
* **Precision**: 96.88%
* **Recall**: 96.83%
* **F1-Score**: 96.84%
* 📉 Kinerja terendah dibanding model lain karena sifatnya yang mudah overfitting tanpa metode pemangkasan.

### 6. **Gradient Boosting**

* **Akurasi**: 98.00%
* **Precision**: 98.02%
* **Recall & F1-Score**: 98.00%
* 🏆 Salah satu model dengan **stabilitas dan presisi tinggi**, unggul dalam menangani pola kompleks.

### 7. **AdaBoost**

* **Akurasi / Precision / Recall / F1-Score**: 97.50%
* ✳️ Model boosting klasik yang memberi bobot pada data sulit. Efektif namun sedikit kalah dari Gradient Boosting dan Random Forest.

---

## 📊 **Perbandingan Singkat**

| Model               | Accuracy   | Precision  | Recall     | F1-Score   |
| ------------------- | ---------- | ---------- | ---------- | ---------- |
| Logistic Regression | 0.9700     | 0.9700     | 0.9700     | 0.9700     |
| Random Forest       | **0.9817** | **0.9818** | **0.9817** | **0.9817** |
| XGBoost             | 0.9783     | 0.9784     | 0.9783     | 0.9783     |
| KNN                 | 0.9750     | 0.9750     | 0.9750     | 0.9750     |
| Decision Tree       | 0.9683     | 0.9688     | 0.9683     | 0.9684     |
| Gradient Boosting   | 0.9800     | 0.9802     | 0.9800     | 0.9800     |
| AdaBoost            | 0.9750     | 0.9750     | 0.9750     | 0.9750     |

---

## 🎯 **Kesimpulan**

* **Random Forest** memberikan performa terbaik secara keseluruhan.
* **Gradient Boosting** dan **XGBoost** juga menunjukkan hasil luar biasa dan cocok untuk deployment model klasifikasi medis.
* **Logistic Regression** tetap relevan karena kesederhanaannya dan interpretabilitas tinggi, meskipun tidak setinggi ensemble method.

# References

- Gao et al., 2023. *Artificial Intelligence and Machine Learning in Lung Cancer Immunotherapy*. Journal of Hematology & Oncology, 16(55). [https://doi.org/10.1186/s13045-023-01456-y](https://doi.org/10.1186/s13045-023-01456-y)  
- Dritsas & Trigka, 2022. *Lung Cancer Risk Prediction with Machine Learning Models*. BDCC, 6(139). [https://doi.org/10.3390/bdcc6040139](https://doi.org/10.3390/bdcc6040139)  
- Li et al., 2022. *Machine Learning for Lung Cancer Diagnosis, Treatment, and Prognosis*. Genomics, Proteomics & Bioinformatics, 20(5): 850–866. [https://doi.org/10.1016/j.gpb.2022.11.003](https://doi.org/10.1016/j.gpb.2022.11.003)
"""

